{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task 2<h1/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат аналізу тональності: [{'label': 'LABEL_1', 'score': 0.5228682160377502}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Аналіз тональності (Sentiment Analysis)\n",
    "from transformers import pipeline\n",
    "\n",
    "# Використання моделі, яка підтримує українську мову\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"xlm-roberta-base\")\n",
    "\n",
    "# Тестовий текст українською\n",
    "text = \"Цей продукт чудовий і приносить радість!\"\n",
    "\n",
    "# Аналіз тональності\n",
    "sentiment_result = sentiment_analyzer(text)\n",
    "print(\"Результат аналізу тональності:\", sentiment_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат класифікації тексту: [{'label': 'LABEL_1', 'score': 0.5718856453895569}]\n"
     ]
    }
   ],
   "source": [
    "# 2. Класифікація тексту\n",
    "# Використання багатомовної моделі для класифікації\n",
    "classifier = pipeline(\"text-classification\", model=\"xlm-roberta-base\")\n",
    "\n",
    "# Класифікація тексту\n",
    "classification_text = \"Штучний інтелект змінює наше життя.\"\n",
    "classification_result = classifier(classification_text)\n",
    "print(\"Результат класифікації тексту:\", classification_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitriy/Desktop/masterDegree/iad/lab4/venv/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат перекладу: I like to study artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Завантаження моделі та токенайзера\n",
    "model_name = \"Helsinki-NLP/opus-mt-uk-en\"\n",
    "translator_tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "translator_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Функція перекладу\n",
    "def translate_text(text):\n",
    "    inputs = translator_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = translator_model.generate(**inputs)\n",
    "    return translator_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Текст для перекладу\n",
    "translation_text = \"Я люблю вивчати штучний інтелект.\"\n",
    "translation_result = translate_text(translation_text)\n",
    "print(\"Результат перекладу:\", translation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат генерації тексту: [{'generated_text': 'Штучний інтелект може допомогтиннне мовешичн'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Генерація тексту (Text Generation)\n",
    "# Використання багатомовної моделі для генерації тексту\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "# Генерація тексту\n",
    "generation_text = \"Штучний інтелект може допомогти\"\n",
    "generation_result = generator(generation_text, max_length=50, num_return_sequences=1)\n",
    "print(\"Результат генерації тексту:\", generation_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
